<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <title>VGG-19 Model and Analysis</title>
  <!-- CSS only -->
<!--Boot Strap-->
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css">

<!--Glyphicons-->
<link href="https://stackpath.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-wvfXpqpZZVQGK6TAh5PVlGOfQNHSoD2xbE+QkPxCAFlNEevoEH3Sl0sibVcOQVnN" crossorigin="anonymous">



<!-- Fonts from google -->
<link rel="preconnect" href="https://fonts.gstatic.com">
<link href="https://fonts.googleapis.com/css2?family=Bungee+Inline&family=Bungee+Shade&family=Chathura:wght@800&family=Girassol&family=Karantina&family=Niconne&family=Odibee+Sans&family=Romanesco&display=swap" rel="stylesheet"></head>

<!-- Our CSS -->
<link rel="stylesheet" type="text/css" href="/static/css/style.css">

<!-- JQuery from google CDN -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>

</head>

<body>

<section>
    <div class="container-fluid">
        <div class="row"> 
            <div class="col-12 mt-4">
                <div class="h1 text-center">
                    <p>Face Mask Detector using TensorFlow VGG-19 and OpenCV2</p><br>                    
                </div>
                <div>
                    <h4>Introduction to Computer Vision</h4>
                    <blockquote class="ml-3 mr-3 mb-1" cite="https://machinelearningmastery.com/what-is-computer-vision/">
                        <q>    <strong>Computer vision is the automated extraction of information from images. Information can mean anything from <em>3D models, camera position, object detection and recognition</em>  to <em>grouping and searching image content</em>.</strong></q>
                    </blockquote>
                    <figcaption><em>— Page ix, Programming Computer Vision with Python, 2012.</em></figcaption>
                    <div class="mt-3">
                        <h6>Why VGG-16?</h6>
                        <p>We tested our dataset with two other TensorFlow Keras models, we decided to go ahead with VGG-16 considering the value loss over training loss. </p>
                    <h6>Objective: </h6>
                      <ul>
                        <li>Detect face masks in images selected</li>
                        <li>Detect face masks in images uploaded</li>
                        <li>Detect face masks in real-time video streams</li>
                      </ul>
                    </div>
                </div>
                <div class="row">
                    <div class="col-xs-12 col-sm-12 col-md-6 col-lg-6 col-xl-6">
                        <div class="text-center">
                            <h4 class="text-center">VGG-19</h4>
                            <img src="../static/Images/vgg16.png" class="image-fluid w-100" height="330px">
                        </div>
                    </div>
                    <div class="col-xs-12 col-sm-12 col-md-6 col-lg-6 col-xl-6">
                        <h4 class="text-center">Convolutional Network for Classification and Detection</h4>
                        <div class="mt-4">
                            <p><strong>Model: </strong>Very Deep Convolutional Networks for Large-Scale Image Recognition proposed by K. Simonyan and A. Zisserman from the University of Oxford</p>
                            <p><strong>ImageNet Dataset: </strong>The model achieves 92.7% top-5 test accuracy in ImageNet, which is a dataset of over 14 million images belonging to 1000 classes.</p>
                            <p class="m-0" cite="https://towardsdatascience.com/step-by-step-vgg16-implementation-in-keras-for-beginners-a833c686ae6c"><strong>CNN: </strong>VGG-19 is focused on having convolution layers of 3x3 filter with a stride 1 and always used same padding and maxpool layer of 2x2 filter of stride 2. It follows this arrangement of convolution and max pool layers consistently throughout the whole architecture. In the end it has 2 FC(fully connected layers) followed by a softmax for output. The 16 in VGG16 refers to it has 16 layers that have weights. </p>
                            <a href="https://neurohive.io/en/popular-networks/vgg16/" alt="vgg-16"><p class="m-0">Learn More</p></a>
                        </div>                        
                    </div>                    
                </div>
                <h4 class="mt-4">Data loading and Visualization</h4>
                <div class="row">                    
                    <div class="col-4">
                        <div class="mt-4">
                            <h6 class="w-100">Folder Structure: </h6>
                            <ul>
                              <li>./Resources
                                <ul style="list-style-type:square;">
                                    <li>/Train
                                        <ul>
                                            <li>/WithMask
                                                <ul>
                                                    <li>/images..</li>
                                                  </ul>
                                            </li>
                                            <li>/WithoutMask
                                                <ul>
                                                    <li>/images..</li>
                                                  </ul>
                                            </li>
                                        </ul>
                                    </li>
                                </ul>
                              </li>
                            </ul>
                        </div>                            
                    </div>
                    <div class="col-4">
                        <h6>Dataframe:</h6>
                            <img src="../static/Images/dataframe.png" class="image-fluid w-100" >
                    </div>
                    <div class="col-4">
                        <img src="../Images/barchart.jpg" class="image-fluid w-100" >
                    </div>
                </div>   
                <h4 class="mt-4">Data Augmentation</h4> 
                <div class="ml-4 mr-4"><p>Nural networks are heavily reliant on big data to avoid overfitting.Since we have limited data,we can solve this problem with <em>Data Augmentation</em>. Data augmentation is a technique to artificially create new training data from existing training data. It will increase the diversity of your training set by applying random (but realistic) transformations such as image rotation.</p> 
                 <p><strong>ImageDataGenerator: </strong>Dataset is augmneted using <em>ImageDataGenerator</em> that accepts the original data, randomly transforms it, and returns only the new, transformed data which will be used in training the model.</p>
                </div>
                <h4 class="mt-4">Building and Training the Model</h4>  
                <div class="ml-4 mr-4">
                    <p>We build our VGG-19 model with Keras Sequential CNN model with various layers such as Flatten, and Dense with activation <em>'softMax'</em>.We used the <em>'RMSProp'</em>> optimizer and <em>‘binary_crossentropy’</em> as our loss function to address the two classes. </p>
                    <p><strong>Test Accuracy: </strong>After 33 epochs, our model achieved the test accuracy of 92%</p>
                    <img src="../Images/Test_accuracy.png" class="image-fluid w-50" >
                </div> 
                <h4 class="mt-4">Model Accuracy and Loss</h4> 
                <div class="row">
                    <div class="col-12 ml-4 mr-4">
                        <img src="../Images/model_loss.jpg" class="image-fluid w-100" >
                        <p class="mb-0"><strong>Note: </strong>As you can see model's Test accuracy is heigher than the training accuracy but there could be slight overfitting after epoch 23.</p>
                        <p><strong>Future Analysis: </strong>We would consider stoping and model from traing using <em>TensorFlow Keras ModelCheckpoint</em>, which lets us save the best model while monitoring the value loss.</p>
                    </div>
                </div>
                <h4 class="mt-4">OpenCV Face Recognision and Mask Prediction using the saved VGGNET model</h4> 
                <div>
                    <p><strong>Haar Cascade: </strong>HaarCascade is an object detection method used to locate an object of interest in images.We used OpenCV <em>.detectMultiScale</em> function with HaarCascade to generate a list of rectangles for all of the detected faces in the image as well as realtime video.</p>
                    <div class="row">
                        <div class="col-6">
                            <h4>Face detection and Mask prediction of an Image</h4>
                            <img src="../Images/analysis_prediction.png" class="image-fluid w-100" >
                        </div>
                        <div class="col-6">
                            <h4>Face detection and Mask prediction real-time</h4>
                        </div>
                    </div>
                </div>
                <h4 class="mt-4">APP Limitations: </h4>  
                <div class="ml-4 mr-4">
                    <p class="mb-0"><strong>OpenCV:</strong></p>
                    <p>Please consider the following points before upoading an image for prediction.</p>
                    <p class="mb-0"><strong>Face Detection: </strong>OpenCV wll not recongnize faces from a busy backgroud.</p>
                    <p class="mb-0"><strong>Minimum Neighbours: </strong>While our app can accuratly predict for two neighbours, OpenCV might behave randmly with more than 2 neighbours.</p>
                    <p class="mb-0"><strong>Face the camera: </strong>OpenCV will not recongnize the face if the person is not facing the camera.</p>
                    <br>
                    <p class="mb-0"><strong>Other: </strong></p>
                    <p class="mb-0"><strong>Browse Option:</strong>Browse option only works if the image uploaded is saved in UploadPic folder.</p>

                </div>         
                


                


            </div>
        </div>
    </div>

</section>


<!-- Javascript files -->
<!-- D3 JavaScript -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/d3/5.5.0/d3.js"></script>

 <!--Our javaScript file-->
  <!---------------------------------------------->

</body>
</html>